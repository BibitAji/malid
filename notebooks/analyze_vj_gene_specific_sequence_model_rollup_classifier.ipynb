{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T18:56:32.577979Z",
     "iopub.status.busy": "2023-08-07T18:56:32.577683Z",
     "iopub.status.idle": "2023-08-07T18:56:38.557602Z",
     "shell.execute_reply": "2023-08-07T18:56:38.556891Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from malid import config, logger\n",
    "import crosseval\n",
    "from malid.trained_model_wrappers import (\n",
    "    VJGeneSpecificSequenceModelRollupClassifier,\n",
    ")\n",
    "from malid.trained_model_wrappers.vj_gene_specific_sequence_classifier import (\n",
    "    SequenceSubsetStrategy,\n",
    ")\n",
    "import pandas as pd\n",
    "import re\n",
    "from summarynb import show\n",
    "from typing import Callable, Optional\n",
    "import numpy as np\n",
    "import multiclass_metrics\n",
    "from malid.datamodels import (\n",
    "    SampleWeightStrategy,\n",
    "    healthy_label,\n",
    "    TargetObsColumnEnum,\n",
    "    GeneLocus,\n",
    ")\n",
    "\n",
    "sample_weight_strategy = config.sample_weight_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T18:56:38.560781Z",
     "iopub.status.busy": "2023-08-07T18:56:38.560164Z",
     "iopub.status.idle": "2023-08-07T18:56:38.566412Z",
     "shell.execute_reply": "2023-08-07T18:56:38.565942Z"
    }
   },
   "outputs": [],
   "source": [
    "config.embedder.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2facbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read this optional flag from environment variables.\n",
    "from environs import Env\n",
    "\n",
    "env = Env()\n",
    "default_sequence_subset_strategy: SequenceSubsetStrategy = (\n",
    "    config.metamodel_base_model_names.base_sequence_model_subset_strategy\n",
    ")\n",
    "sequence_subset_strategy: SequenceSubsetStrategy = env.enum(\n",
    "    \"SEQUENCE_SUBSET_STRATEGY\",\n",
    "    type=SequenceSubsetStrategy,\n",
    "    ignore_case=True,\n",
    "    # Pass .name as default here, because matching happens on string name:\n",
    "    # The internal \"if enum_value.name.lower() == value.lower()\" will fail unless value is the .name. The enum object itself doesn't have a .lower()\n",
    "    default=default_sequence_subset_strategy.name,\n",
    ")\n",
    "sequence_subset_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T18:56:38.568318Z",
     "iopub.status.busy": "2023-08-07T18:56:38.567999Z",
     "iopub.status.idle": "2023-08-07T18:56:38.583387Z",
     "shell.execute_reply": "2023-08-07T18:56:38.582916Z"
    }
   },
   "outputs": [],
   "source": [
    "base_model_fold_label_train = \"train_smaller1\"\n",
    "rollup_model_fold_label_train = \"train_smaller2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T18:56:38.585656Z",
     "iopub.status.busy": "2023-08-07T18:56:38.585348Z",
     "iopub.status.idle": "2023-08-07T18:56:38.597641Z",
     "shell.execute_reply": "2023-08-07T18:56:38.597170Z"
    }
   },
   "outputs": [],
   "source": [
    "base_classifier = sequence_subset_strategy.base_model\n",
    "base_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-07T18:56:38.599959Z",
     "iopub.status.busy": "2023-08-07T18:56:38.599548Z",
     "iopub.status.idle": "2023-08-07T18:57:45.502857Z",
     "shell.execute_reply": "2023-08-07T18:57:45.502239Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_available_base_model_names(sequence_models_base_dir):\n",
    "    # Auto-detect available base sequence model names\n",
    "    # TODO: Use the list of available base models configured in training script.\n",
    "    for dirname in (\n",
    "        sequence_models_base_dir\n",
    "        / f\"rollup_models_specialized_for_{base_classifier.split_short_name}\"\n",
    "    ).glob(f\"base_model_*_trained_on_{base_model_fold_label_train}\"):\n",
    "        model_name_search = re.search(\n",
    "            r\"base_model_(.*)_trained_on\", str(dirname)\n",
    "        )  # returns None if nothing found\n",
    "        if model_name_search:\n",
    "            yield model_name_search.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab54223",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "for gene_locus in config.gene_loci_used:\n",
    "    for target_obs_column in config.classification_targets:\n",
    "        try:\n",
    "            target_obs_column.confirm_compatibility_with_gene_locus(gene_locus)\n",
    "            target_obs_column.confirm_compatibility_with_cross_validation_split_strategy(\n",
    "                config.cross_validation_split_strategy\n",
    "            )\n",
    "        except Exception as err:\n",
    "            # Skip invalid combinations\n",
    "            logger.warning(f\"{err}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        display(\n",
    "            Markdown(f\"## {gene_locus}, {target_obs_column}, {sample_weight_strategy}\")\n",
    "        )\n",
    "        sequence_models_base_dir = base_classifier._get_model_base_dir(\n",
    "            gene_locus=gene_locus,\n",
    "            target_obs_column=target_obs_column,\n",
    "            sample_weight_strategy=sample_weight_strategy,\n",
    "        )\n",
    "        for base_sequence_model_name in get_available_base_model_names(\n",
    "            sequence_models_base_dir\n",
    "        ):\n",
    "            models_base_dir = (\n",
    "                VJGeneSpecificSequenceModelRollupClassifier._get_model_base_dir(\n",
    "                    sequence_models_base_dir=sequence_models_base_dir,\n",
    "                    base_sequence_model_name=base_sequence_model_name,\n",
    "                    base_model_train_fold_label=base_model_fold_label_train,\n",
    "                    split_short_name=base_classifier.split_short_name,\n",
    "                )\n",
    "            )  # should already exist\n",
    "\n",
    "            output_base_dir = (\n",
    "                VJGeneSpecificSequenceModelRollupClassifier._get_output_base_dir(\n",
    "                    sequence_model_output_base_dir=base_classifier._get_output_base_dir(\n",
    "                        gene_locus=gene_locus,\n",
    "                        target_obs_column=target_obs_column,\n",
    "                        sample_weight_strategy=sample_weight_strategy,\n",
    "                    ),\n",
    "                    base_sequence_model_name=base_sequence_model_name,\n",
    "                    base_model_train_fold_label=base_model_fold_label_train,\n",
    "                    split_short_name=base_classifier.split_short_name,\n",
    "                )\n",
    "            )  # might not yet exist\n",
    "            output_base_dir.mkdir(parents=True, exist_ok=True)  # create if needed\n",
    "\n",
    "            model_output_prefix = (\n",
    "                models_base_dir / f\"{rollup_model_fold_label_train}_model\"\n",
    "            )\n",
    "            results_output_prefix = (\n",
    "                output_base_dir / f\"{rollup_model_fold_label_train}_model\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                logger.debug(\n",
    "                    f\"{gene_locus}, {target_obs_column}, {sample_weight_strategy}, base model {base_sequence_model_name} from {model_output_prefix} to {results_output_prefix}\"\n",
    "                )\n",
    "\n",
    "                ## Load and summarize\n",
    "                experiment_set = crosseval.ExperimentSet.load_from_disk(\n",
    "                    output_prefix=model_output_prefix\n",
    "                )\n",
    "\n",
    "                # Remove global fold (we trained global fold model, but now get evaluation scores on cross-validation folds only)\n",
    "                # TODO: make kdict support: del self.model_outputs[:, fold_id]\n",
    "                for key in experiment_set.model_outputs[:, -1].keys():\n",
    "                    logger.debug(f\"Removing {key} (global fold)\")\n",
    "                    del experiment_set.model_outputs[key]\n",
    "\n",
    "                experiment_set_global_performance = experiment_set.summarize()\n",
    "                func_generate_classification_report_fname = (\n",
    "                    lambda model_name: f\"{results_output_prefix}.classification_report.{model_name}.txt\"\n",
    "                )\n",
    "                func_generate_confusion_matrix_fname = (\n",
    "                    lambda model_name: f\"{results_output_prefix}.confusion_matrix.{model_name}.png\"\n",
    "                )\n",
    "                experiment_set_global_performance.export_all_models(\n",
    "                    func_generate_classification_report_fname=func_generate_classification_report_fname,\n",
    "                    func_generate_confusion_matrix_fname=func_generate_confusion_matrix_fname,\n",
    "                    dpi=72,\n",
    "                )\n",
    "\n",
    "                # Note that the confusion matrix is hard to interpret here:\n",
    "                # We use OvR classifiers along with different sets of features,\n",
    "                # so the class probabilities are not necessarily comparable and choosing the class with highest probability as winning label is not appropriate.\n",
    "                # For this reason, model3-aggregation label evaluation is a fraught exercise. But the AUC is still evaluatable.\n",
    "                # See malid/train/train_vj_gene_specific_sequence_model_rollup.py for further discussion.\n",
    "\n",
    "                # Before generating model comparison stats, add a metric that excludes the Healthy class.\n",
    "                # Rationale: Predicting that sequences are \"healthy\" is hard to reason about.\n",
    "                # We may not even want to be taking this into consideration when choosing the version of model 3 that goes into the metamodel.\n",
    "                # Do this only for main disease classification target.\n",
    "                if target_obs_column == TargetObsColumnEnum.disease:\n",
    "                    # Here we add an extra AUC measure that is restricted to disease classes only:\n",
    "                    # - we subset y_true and y_score by removing rows where y_true == healthy,\n",
    "                    # - and we also remove healthy class predicted probabilities so those don't get included in the multiclass AUC averaging.\n",
    "                    def score_wrapper_excluding_a_class(\n",
    "                        y_true: np.ndarray,\n",
    "                        y_score: np.ndarray,\n",
    "                        exclude: str,\n",
    "                        func: Callable,\n",
    "                        labels: Optional[np.ndarray] = None,\n",
    "                        sample_weight: Optional[np.ndarray] = None,\n",
    "                        **kwargs,\n",
    "                    ):\n",
    "                        y_score = np.array(y_score)\n",
    "                        y_true = np.array(y_true)\n",
    "\n",
    "                        # Remove examples where ground truth label matches label-to-exclude\n",
    "                        mask = y_true != exclude\n",
    "                        y_score = y_score[mask, :]\n",
    "                        y_true = y_true[mask]\n",
    "                        if sample_weight is not None:\n",
    "                            sample_weight = np.array(sample_weight)\n",
    "                            sample_weight = sample_weight[mask]\n",
    "\n",
    "                        # Remove predicted classes where label matches label-to-exclude\n",
    "                        # (probabilities will no longer sum to 1)\n",
    "                        if labels is not None and exclude in labels:\n",
    "                            labels = np.array(labels)\n",
    "                            mask = labels != exclude\n",
    "                            y_score = y_score[:, mask]\n",
    "                            labels = labels[mask]\n",
    "\n",
    "                        # Call original function with modified data\n",
    "                        return func(\n",
    "                            y_true,\n",
    "                            y_score,\n",
    "                            labels=labels,\n",
    "                            sample_weight=sample_weight,\n",
    "                            **kwargs,\n",
    "                        )\n",
    "\n",
    "                    # Wire up the new metric, like we do in crosseval.DEFAULT_PROBABILITY_SCORERS\n",
    "                    custom_probability_scorers = crosseval.DEFAULT_PROBABILITY_SCORERS | {\n",
    "                        \"rocauc_without_healthy\": (\n",
    "                            score_wrapper_excluding_a_class,\n",
    "                            \"ROC-AUC without Healthy (weighted OvO)\",\n",
    "                            {\n",
    "                                # Label to be removed:\n",
    "                                \"exclude\": healthy_label,\n",
    "                                # It will call this function after modifying the data to remove healthy_label:\n",
    "                                \"func\": multiclass_metrics.roc_auc_score,\n",
    "                                # Standard kwargs, as in crosseval.DEFAULT_PROBABILITY_SCORERS:\n",
    "                                \"average\": \"weighted\",\n",
    "                                \"multi_class\": \"ovo\",\n",
    "                            },\n",
    "                        ),\n",
    "                    }\n",
    "                else:\n",
    "                    # pass None to get default values\n",
    "                    custom_probability_scorers = None\n",
    "                combined_stats = (\n",
    "                    experiment_set_global_performance.get_model_comparison_stats(\n",
    "                        probability_scorers=custom_probability_scorers,\n",
    "                    )\n",
    "                )\n",
    "                combined_stats.to_csv(\n",
    "                    f\"{results_output_prefix}.compare_model_scores.tsv\",\n",
    "                    sep=\"\\t\",\n",
    "                )\n",
    "                display(Markdown(f\"### Base model {base_sequence_model_name}\"))\n",
    "                display(combined_stats)\n",
    "\n",
    "                # Show the saved confusion matrices\n",
    "                model_names = combined_stats.index\n",
    "                # exclude dummies\n",
    "                model_names = model_names[~model_names.str.startswith(\"dummy\")]\n",
    "                show(\n",
    "                    [\n",
    "                        #         [\n",
    "                        #             func_generate_classification_report_fname(model_name)\n",
    "                        #             for model_name in model_names\n",
    "                        #         ],\n",
    "                        [\n",
    "                            func_generate_confusion_matrix_fname(model_name)\n",
    "                            for model_name in model_names\n",
    "                        ],\n",
    "                    ],\n",
    "                    headers=[\n",
    "                        f\"Rollup model: {model_name}\" for model_name in model_names\n",
    "                    ],\n",
    "                    max_width=500,\n",
    "                )\n",
    "\n",
    "            except Exception as err:\n",
    "                logger.exception(\n",
    "                    f\"Failed to analyze {gene_locus}, {target_obs_column}, {sample_weight_strategy}, base model {base_sequence_model_name}: {err}\"\n",
    "                )\n",
    "\n",
    "            print(\"*\" * 80)\n",
    "        # Done with this target+locus\n",
    "        display(Markdown(f\"---\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd2ad763",
   "metadata": {},
   "source": [
    "# Report on the best-performing model for each locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9864cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_summary(\n",
    "    gene_locus: GeneLocus,\n",
    "    target_obs_column: TargetObsColumnEnum,\n",
    "    sample_weight_strategy: SampleWeightStrategy,\n",
    "    top_N_base_models_to_investigate_aggregation_models: int = 3,\n",
    "):\n",
    "    display(Markdown(f\"## {gene_locus}, {target_obs_column}, {sample_weight_strategy}\"))\n",
    "    # Two ways to sort the results:\n",
    "    for sort_col_description, sort_col_name in [\n",
    "        (\"normally\", \"ROC-AUC (weighted OvO) per fold\"),\n",
    "        (\n",
    "            # This sort column is not always present. It's only added for disease classification target.\n",
    "            # Below, we will gracefully skip this sort column if it's not present.\n",
    "            \"diseases only without healthy\",\n",
    "            \"ROC-AUC without Healthy (weighted OvO) per fold\",\n",
    "        ),\n",
    "    ]:\n",
    "        # Re-using code from above to generate output file paths\n",
    "        sequence_models_base_dir = base_classifier._get_model_base_dir(\n",
    "            gene_locus=gene_locus,\n",
    "            target_obs_column=target_obs_column,\n",
    "            sample_weight_strategy=sample_weight_strategy,\n",
    "        )\n",
    "        results = {}\n",
    "        results_single_row = {}\n",
    "        # Loop over base models\n",
    "        for base_sequence_model_name in get_available_base_model_names(\n",
    "            sequence_models_base_dir\n",
    "        ):\n",
    "            # Given a base model:\n",
    "            # Load rollup model performance comparison spreadsheet\n",
    "            output_base_dir = (\n",
    "                VJGeneSpecificSequenceModelRollupClassifier._get_output_base_dir(\n",
    "                    sequence_model_output_base_dir=base_classifier._get_output_base_dir(\n",
    "                        gene_locus=gene_locus,\n",
    "                        target_obs_column=target_obs_column,\n",
    "                        sample_weight_strategy=sample_weight_strategy,\n",
    "                    ),\n",
    "                    base_sequence_model_name=base_sequence_model_name,\n",
    "                    base_model_train_fold_label=base_model_fold_label_train,\n",
    "                    split_short_name=base_classifier.split_short_name,\n",
    "                )\n",
    "            )\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    output_base_dir\n",
    "                    / f\"{rollup_model_fold_label_train}_model.compare_model_scores.tsv\",\n",
    "                    sep=\"\\t\",\n",
    "                    index_col=0,\n",
    "                )\n",
    "            except FileNotFoundError:\n",
    "                # If the file is not found, skip to the next base model\n",
    "                logger.warning(\n",
    "                    f\"Results file not found for {gene_locus}, {target_obs_column}, {sample_weight_strategy}, base model {base_sequence_model_name}. See earlier in this notebook for possible errors generating that file.\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            if sort_col_name not in df.columns:\n",
    "                # If sort column does not exist in the data, skip to the next sort column\n",
    "                # (We are actually probably ok to use break instead of continue here: if the sort column is missing, it should be missing for all base models, so we can't do anything with this sort column.\n",
    "                # But just in case, we use continue to skip to the next sort column only after trying all base models, just in case there's a reason some base models might have the sort column while others don't.)\n",
    "                continue\n",
    "\n",
    "            results[base_sequence_model_name] = df.sort_values(\n",
    "                sort_col_name, ascending=False\n",
    "            )\n",
    "            # Keep only the best-performing rollup model for each base model\n",
    "            # In other words, we choose only one row (best performance) for each base model\n",
    "            results_single_row[base_sequence_model_name] = results[\n",
    "                base_sequence_model_name\n",
    "            ].iloc[0]\n",
    "\n",
    "        if not results_single_row:\n",
    "            # If no results were added (due to missing sort columns), continue to next sort_col_name\n",
    "            continue\n",
    "\n",
    "        results_single_row = pd.DataFrame(results_single_row).T.sort_values(\n",
    "            sort_col_name, ascending=False\n",
    "        )\n",
    "        # put the sort column first\n",
    "        displayed_column_order = [sort_col_name] + [\n",
    "            col for col in results_single_row.columns if col != sort_col_name\n",
    "        ]\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"### Evaluating {sort_col_description}: best performance for each base model:\"\n",
    "            )\n",
    "        )\n",
    "        display(results_single_row[displayed_column_order])\n",
    "\n",
    "        # Then zoom into the top N performing base models, and show the rollup model options for them.\n",
    "        for base_model in results_single_row.index[\n",
    "            :top_N_base_models_to_investigate_aggregation_models\n",
    "        ]:\n",
    "            display(\n",
    "                Markdown(f\"#### Base model {base_model} has aggregation model options:\")\n",
    "            )\n",
    "            # put the sort column first\n",
    "            displayed_column_order = [sort_col_name] + [\n",
    "                col for col in results[base_model].columns if col != sort_col_name\n",
    "            ]\n",
    "            display(results[base_model].head(n=3)[displayed_column_order])\n",
    "\n",
    "        display(Markdown(f\"---\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gene_locus in config.gene_loci_used:\n",
    "    for target_obs_column in config.classification_targets:\n",
    "        show_summary(gene_locus, target_obs_column, sample_weight_strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "py39-cuda-env",
   "language": "python",
   "name": "py39-cuda-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
